_wandb:
    value:
        cli_version: 0.18.3
        m:
            - "1": validation_policy_gradient_loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": trainer/global_step
              "6":
                - 3
              "7": []
            - "1": validation_policy_gradient_reward_mean
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": policy_gradient_loss_epoch
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": policy_gradient_reward_mean_epoch
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": validation_mle_loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": epoch
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": mle_loss_epoch
              "5": 2
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.11.8
        t:
            "1":
                - 1
                - 9
                - 11
                - 49
                - 55
                - 95
                - 103
            "2":
                - 1
                - 9
                - 11
                - 49
                - 55
                - 95
                - 103
            "3":
                - 7
                - 23
                - 55
                - 66
            "4": 3.11.8
            "5": 0.18.3
            "6": 4.37.2
            "8":
                - 5
            "12": 0.18.3
            "13": linux-x86_64
bart_score_dir:
    value: /data/agirard/Projects/TimeTravel-PolicyGradientRL/src/BARTScore_metric
bart_scorer_checkpoint:
    value: facebook/bart-large-cnn
baseline_score:
    value: 0.5
batch_size:
    value: 4
bert_scorer_batch_size:
    value: 1
bert_scorer_model_type:
    value: microsoft/deberta-xlarge-mnli
data_dir:
    value: /data/agirard/Projects/TimeTravel-PolicyGradientRL/data/transformed
dev_file:
    value: dev_data_sample.json
file_label:
    value: _pg_model2
learning_rate:
    value: 2e-05
logs_dir:
    value: /data/agirard/Projects/TimeTravel-PolicyGradientRL/logs
max_epochs_mle:
    value: 2
max_epochs_pg:
    value: 3
max_gen_length:
    value: 250
max_length:
    value: 512
mle_epochs_model1:
    value: 1
mle_epochs_model2:
    value: 1
model_dir:
    value: /data/agirard/Projects/TimeTravel-PolicyGradientRL/models/model2_2024-10-30-16
model_name:
    value: google/flan-t5-base
models_dir:
    value: /data/agirard/Projects/TimeTravel-PolicyGradientRL/models
num_workers:
    value: 3
output_attentions:
    value: false
pg_epochs_model2:
    value: 1
results_dir:
    value: /data/agirard/Projects/TimeTravel-PolicyGradientRL/results
reward_metric:
    value: rouge
root_dir:
    value: /data/agirard/Projects/TimeTravel-PolicyGradientRL
scorer_device:
    value: cuda:0
shuffle:
    value: true
test_file:
    value: test_data_sample.json
train_file:
    value: train_supervised_small_sample.json
use_bart:
    value: false
use_bert:
    value: false
use_bleu:
    value: false
use_custom_loss:
    value: true
